{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq_-Smt7vrx1",
        "outputId": "2eba80e2-710b-4b32-c75f-77f05903204e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "from numba import cuda\n",
        "from time import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def create_matrix(n):\n",
        "  a = np.random.randint(0, 10, (n, n)).astype(np.float64)\n",
        "  b = np.random.randint(0, 10, (n, n)).astype(np.float64)\n",
        "  c = np.zeros((n, n)).astype(np.float64)\n",
        "  return a, b, c\n",
        "\n",
        "def mul_cpu_element(a, b):\n",
        "  n=len(a)\n",
        "  c = np.zeros((n,n))\n",
        "  start = time()\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      for k in range(n):\n",
        "        c[i, j] += a[i,k] * b[k,j]\n",
        "  return c, time()-start\n",
        "    \n",
        "def mul_cpu_vector(a, b):\n",
        "  n=len(a)\n",
        "  c = np.zeros((n,n))\n",
        "  start = time()\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      c[i, j] = np.dot(a[i,:], b[:,j])\n",
        "  return c, time()-start\n",
        "\n",
        "def mul_cpu_matrix(a, b):\n",
        "  start = time()\n",
        "  c = np.dot(a, b)\n",
        "  return c, time() - start\n",
        "\n",
        "@cuda.jit\n",
        "def gpu_mul_operation(a, b, c):\n",
        "    i, j = cuda.grid(2)\n",
        "    if i < c.shape[0] and j < c.shape[1]:\n",
        "      tmp = 0\n",
        "      for k in range(a.shape[1]):\n",
        "        tmp += a[i, k] * b[k, j]\n",
        "      c[i, j] = tmp\n",
        "\n",
        "@cuda.jit\n",
        "def gpu_mul_operation(a, b, c):\n",
        "    i, j = cuda.grid(2)\n",
        "    if i < c.shape[0] and j < c.shape[1]:\n",
        "      tmp = 0\n",
        "      for k in range(a.shape[1]):\n",
        "        tmp += a[i, k] * b[k, j]\n",
        "      c[i, j] = tmp\n",
        "\n",
        "@cuda.jit\n",
        "def gpu_mul_element(a, b, c):\n",
        "    i, j = cuda.grid(2)\n",
        "    if i < c.shape[0] and j < c.shape[1]:\n",
        "      tmp = 0\n",
        "      for k in range(a.shape[1]):\n",
        "        tmp += a[i, k] * b[k, j]\n",
        "      c[i, j] = tmp\n",
        "\n",
        "@cuda.jit\n",
        "def gpu_mul_vector(a, b, c):\n",
        "    i, j = cuda.grid(2)\n",
        "    tmp = 0\n",
        "    for k in range(a.shape[1]):\n",
        "      tmp += a[i, k] * b[k, j]\n",
        "    c[i, j] = tmp\n",
        "\n",
        "def prepare_and_exec_gpu_mul(a, b, c, n, gpu_func):\n",
        "  tread_number_block = 32\n",
        "\n",
        "  a_global = cuda.to_device(a)\n",
        "  b_global = cuda.to_device(b)\n",
        "  c_global = cuda.device_array((n, n))\n",
        "    \n",
        "  threadsperblock = (tread_number_block, tread_number_block)\n",
        "  blockspergrid_x = int(math.ceil(a.shape[0] / threadsperblock[1]))\n",
        "  blockspergrid_y = int(math.ceil(b.shape[1] / threadsperblock[0]))\n",
        "  blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "  start = time()\n",
        "  gpu_func[blockspergrid, threadsperblock](a_global, b_global, c_global)\n",
        "  gpu_time = time() - start\n",
        "  c_gpu = c_global.copy_to_host() \n",
        "  return c_gpu, gpu_time\n",
        "\n",
        "def expiriens(n, count, cpu_func, gpu_func, message):  \n",
        "  gpu_time_sum = 0\n",
        "  cpu_time_sum = 0\n",
        "  for _ in range(count):\n",
        "    a, b, c = create_matrix(n)\n",
        "    c_gpu, gpu_time = prepare_and_exec_gpu_mul(a, b, c, n, gpu_func)\n",
        "    gpu_time_sum+=gpu_time\n",
        "    c_cpu, cpu_time = cpu_func(a, b)\n",
        "    cpu_time_sum+=cpu_time\n",
        "\n",
        "  print('Размерность матрицы', n)\n",
        "  print('Усредненное время умножения на CPU (', message, '):', cpu_time/count)\n",
        "  print('Усредненное время умножения на GPU (', message, '):', gpu_time/count)\n",
        "  print('Ускорение',cpu_time/gpu_time )\n",
        "  return cpu_time/gpu_time\n",
        "\n",
        "def functions_are_correct(n, cpu_func, gpu_func, message):\n",
        "  a, b, c = create_matrix(n)\n",
        "  c_numpy = mul_cpu_matrix(a,b)[0]\n",
        "  c_cpu = cpu_func(a,b)[0]\n",
        "  c_gpu = prepare_and_exec_gpu_mul(a, b, c, n, gpu_func)[0]\n",
        "  if np.array_equal(c_numpy, c_cpu):\n",
        "    print('CPU считает корректно (', message, ')')\n",
        "  if np.array_equal(c_numpy, c_gpu):\n",
        "    print('GPU считает корректно (', message, ')')\n",
        "\n",
        "def lab(cpu_func, gpu_func, message):\n",
        "  print(message)\n",
        "  a, b, c = get_matrix(128)\n",
        "  functions_are_correct(128, cpu_func, gpu_func, message)\n",
        "  count = 1\n",
        "  n_array = [128, 256, 512, 1024, 2048]\n",
        "  time_array = [expiriens(n_array_i, count, cpu_func, gpu_func, 'поэлементное умножение') for n_array_i in n_array]\n",
        "\n",
        "  plt.plot(np.array(n_array), np.array(time_array)) \n",
        "  plt.xlabel('Размерность')\n",
        "  plt.ylabel('Ускорение')\n",
        "  plt.title(message)\n",
        "  plt.show()\n",
        "\n",
        "lab(mul_cpu_element, gpu_mul_element, 'поэлементное умножение')\n",
        "lab(mul_cpu_element, gpu_mul_element, 'векторное умножение')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "поэлементное умножение\n",
            "CPU считает корректно ( поэлементное умножение )\n",
            "GPU считает корректно ( поэлементное умножение )\n",
            "Размерность матрицы 128\n",
            "Усредненное время умножения на CPU ( поэлементное умножение ): 1.4245102405548096\n",
            "Усредненное время умножения на GPU ( поэлементное умножение ): 0.00031876564025878906\n",
            "Ускорение 4468.832460732984\n",
            "Размерность матрицы 256\n",
            "Усредненное время умножения на CPU ( поэлементное умножение ): 11.336852312088013\n",
            "Усредненное время умножения на GPU ( поэлементное умножение ): 0.0003833770751953125\n",
            "Ускорение 29571.023009950248\n",
            "Размерность матрицы 512\n",
            "Усредненное время умножения на CPU ( поэлементное умножение ): 88.15948557853699\n",
            "Усредненное время умножения на GPU ( поэлементное умножение ): 0.00048041343688964844\n",
            "Ускорение 183507.53498759304\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}